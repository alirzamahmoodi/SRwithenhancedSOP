# Speech-to-Text Transcription Module (`transcribe.py`)

## Purpose

This module is responsible for sending the extracted audio data to an external speech-to-text service (configured as Google Gemini in the current implementation) and processing the response to generate a structured text report.

## Class: `Transcribe`

*   Encapsulates the logic for interacting with the transcription API.
*   Initialized with the application `config` dictionary, which contains API credentials and model settings.

## Main Method: `transcribe(self, dcm_path, audio_path)`

*   **Purpose:** Executes the transcription process.
*   **Parameters:**
    *   `dcm_path` (str): Path to the original DICOM file (potentially used for metadata context, though current docs don't emphasize this).
    *   `audio_path` (str): Path to the temporary WAV audio file generated by `extract_audio.py`.
*   **Returns:**
    *   `str` or `list`: The transcribed text report. The exact format (e.g., single string, list of strings, JSON string) depends on the specific implementation within the method and how the API response is parsed.
*   **Raises:**
    *   Errors related to API authentication or connection (e.g., `google.api_core.exceptions.PermissionDenied`, `google.api_core.exceptions.ServiceUnavailable`).
    *   Errors related to audio file handling (though primarily handled by `extract_audio`).
    *   Errors related to parsing the API response.
*   **Workflow:**
    1.  Initializes the connection to the AI service using credentials from `config` (e.g., `genai.configure(api_key=...)`).
    2.  Selects the specified AI model (e.g., `genai.GenerativeModel(...)`).
    3.  May upload the audio file (`audio_path`) to the service or process it directly.
    4.  Sends the request to the AI service to perform transcription.
    5.  Receives the response from the AI service.
    6.  Parses the response to extract the relevant transcribed text.
    7.  (Potentially) Formats the text into a structured report (e.g., Findings/Conclusion sections).
    8.  Returns the final report text.

## Key Functionality

*   **AI Service Integration:** Connects to and interacts with the configured cloud-based transcription service.
*   **API Credential Management:** Uses API keys/credentials from `config.yaml`.
*   **Audio Data Handling:** Sends the audio data from the temporary file to the API.
*   **Response Processing:** Parses the structured or unstructured text returned by the API.
*   **(Optional) Report Structuring:** May apply logic to format the transcription into specific sections.

## Configuration Requirements (`config.yaml`)

Requires settings specific to the chosen AI service, for example:

```yaml
# ----------------- AI Services (Example: Gemini) -----------------
GEMINI_API_KEY: "your_api_key"
MODEL_NAME: "gemini-1.5-flash"
# Optional: Parameters controlling transcription behavior (e.g., temperature)
# transcription_temperature: 0.8
```

## Error Handling

*   Should handle API-specific errors (authentication, rate limits, timeouts, service unavailability).
*   May implement retry logic with backoff for transient network or API errors.

## Dependencies

*   Specific library for the AI service (e.g., `google-generativeai` for Gemini).
*   Potentially `pydantic` if used for response model validation.
*   `logging` for errors and progress.

## Integration

*   Called by `main.py` in the `run_pipeline` function after audio extraction.
*   Receives the temporary WAV file path from `extract_audio.py`.
*   The returned report text is passed to `database_operations.save_transcription` (for MongoDB) and potentially `store_transcribed_report.py` (for Oracle).

## Related Documents
- [System Architecture](../high_level/architecture.md)
- [Configuration Reference](../high_level/config_reference.md)
- [Audio Extraction Module](extract_audio.md)